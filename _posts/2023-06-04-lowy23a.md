---
title: Stochastic Differentially Private and Fair Learning
booktitle: Proceedings of the Workshop on Algorithmic Fairness through the Lens of
  Causality and Privacy
year: '2022'
abstract: Machine learning models are increasingly used in high-stakes decision-making
  systems. In such applications, a major concern is that these models sometimes discriminate
  against certain demographic groups such as individuals with certain race, gender,
  or age. Another major concern in these applications is the violation of the privacy
  of users. While <em>fair learning</em> algorithms have been developed to mitigate
  discrimination issues, these algorithms can still <em>leak</em> sensitive information,
  such as individuals’ health or financial records. Utilizing the notion of <em>differential
  privacy (DP)</em>, prior works aimed at developing learning algorithms that are
  both private and fair. However, existing algorithms for DP fair learning are either
  not guaranteed to converge or require full batch of data in each iteration of the
  algorithm to converge. In this paper, we provide the first <em>stochastic</em> differentially
  private algorithm for fair learning that is guaranteed to converge. Here, the term
  “stochastic” refers to the fact that our proposed algorithm converges even when
  <em>minibatches</em> of data are used at each iteration (i.e. <em>stochastic optimization</em>).
  Our framework is flexible enough to permit different fairness notions, including
  demographic parity and equalized odds. In addition, our algorithm can be applied
  to non-binary classification tasks with multiple (non-binary) sensitive attributes.
  As a byproduct of our convergence analysis, we provide the first utility guarantee
  for a DP algorithm for solving nonconvex-strongly concave min-max problems. Our
  numerical experiments show that the proposed algorithm <em>consistently offers significant
  performance gains over the state-of-the-art baselines</em>, and can be applied to
  larger scale problems with non-binary target/sensitive attributes.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lowy23a
month: 0
tex_title: Stochastic Differentially Private and Fair Learning
firstpage: 86
lastpage: 119
page: 86-119
order: 86
cycles: false
bibtex_author: Lowy, Andrew and Gupta, Devansh and Razaviyayn, Meisam
author:
- given: Andrew
  family: Lowy
- given: Devansh
  family: Gupta
- given: Meisam
  family: Razaviyayn
date: 2023-06-04
address: 
container-title: Proceedings of the Workshop on Algorithmic Fairness through the Lens
  of Causality and Privacy
volume: '214'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 6
  - 4
pdf: https://proceedings.mlr.press/v214/lowy23a/lowy23a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v214/lowy23a/lowy23a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
